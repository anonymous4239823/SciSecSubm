{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No IPv4 address found on anpi0 !\n",
      "WARNING: No IPv4 address found on anpi1 !\n",
      "WARNING: more No IPv4 address found on en3 !\n"
     ]
    }
   ],
   "source": [
    "from src.utils.flow import *\n",
    "from src.utils.flow_calculations import *\n",
    "from src.utils.restoration import *\n",
    "from src.utils.truncated_packet import *\n",
    "from src.operations.size_perturbation_logic import *\n",
    "from src.operations.timing_perturbation_logic import *\n",
    "from src.operations.calculate_fitness import *\n",
    "\n",
    "modified_pcap_path = \"../data/interim/testing_small_perturbed.pcapng\"\n",
    "pcap_file_path = '../data/raw/botnet-capture-20110816-donbot.pcap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_packets = create_truncated_packets_from_pcap(pcap_file_path)\n",
    "truncated_packets = assign_flow_ids_to_packets(truncated_packets)\n",
    "flow_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights(length, focus_point='middle', scaling_factor=1.0):\n",
    "    \"\"\"\n",
    "    Generates weights for adjusting sizes or timestamps based on a normal distribution,\n",
    "    focused on a specific part of the sequence with a scaling factor.\n",
    "    \"\"\"\n",
    "    if length == 0:\n",
    "        return np.ones(1)\n",
    "    x = np.linspace(0, length, num=length)\n",
    "    if focus_point == 'start':\n",
    "        mean = length * 0.25\n",
    "    elif focus_point == 'end':\n",
    "        mean = length * 0.75\n",
    "    else:  # 'middle'\n",
    "        mean = length / 2\n",
    "    std_dev = length / 10  # Control the spread of the influence\n",
    "    weights = norm.pdf(x, loc=mean, scale=std_dev)\n",
    "    if np.max(weights) == 0:\n",
    "        # If the maximum weight is 0, avoid division by zero.\n",
    "        return np.full(length, scaling_factor)\n",
    "    weights /= np.max(weights)  # Normalize\n",
    "    weights = weights * (scaling_factor - 1) + 1  # Adjust scaling\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_packet_size_approx(flow_stats, direction=0, scaling_factor=1.0, focus_point='middle'):\n",
    "    \"\"\"\n",
    "    Modyfikuje wybrane kierunki przepływu danych (src->dst, dst->src, lub oba),\n",
    "    a następnie zwraca pełne statystyki sumaryczne dla przepływu.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja statystyk przepływu\n",
    "    modified_stats = flow_stats.copy()\n",
    "\n",
    "    # Obliczenie wag dla każdego kierunku, jeśli potrzebne\n",
    "    if direction in [0, 1]:  # src->dst lub oba\n",
    "        total_fwd_packets = flow_stats['tot_fwd_pkts']\n",
    "        if total_fwd_packets > 0:\n",
    "            fwd_weights = generate_weights(total_fwd_packets, focus_point=focus_point, scaling_factor=scaling_factor)\n",
    "            modified_stats['fwd_pkt_len_mean'] = np.mean(fwd_weights) * flow_stats['fwd_pkt_len_mean']\n",
    "            modified_stats['fwd_pkt_len_min'] = np.min(fwd_weights) * flow_stats['fwd_pkt_len_mean']\n",
    "            modified_stats['fwd_pkt_len_max'] = np.max(fwd_weights) * flow_stats['fwd_pkt_len_mean']\n",
    "            modified_stats['fwd_pkt_len_std'] = np.std(fwd_weights) * flow_stats['fwd_pkt_len_std'] if flow_stats['fwd_pkt_len_std'] > 0 else 0\n",
    "            modified_stats['totlen_fwd_pkts'] = np.sum(fwd_weights) * flow_stats['fwd_pkt_len_mean']\n",
    "\n",
    "    if direction in [0, 2]:  # dst->src lub oba\n",
    "        total_bwd_packets = flow_stats['tot_bwd_pkts']\n",
    "        if total_bwd_packets > 0:\n",
    "            bwd_weights = generate_weights(total_bwd_packets, focus_point=focus_point, scaling_factor=scaling_factor)\n",
    "            modified_stats['bwd_pkt_len_mean'] = np.mean(bwd_weights) * flow_stats['bwd_pkt_len_mean']\n",
    "            modified_stats['bwd_pkt_len_min'] = np.min(bwd_weights) * flow_stats['bwd_pkt_len_mean']\n",
    "            modified_stats['bwd_pkt_len_max'] = np.max(bwd_weights) * flow_stats['bwd_pkt_len_mean']\n",
    "            modified_stats['bwd_pkt_len_std'] = np.std(bwd_weights) * flow_stats['bwd_pkt_len_std'] if flow_stats['bwd_pkt_len_std'] > 0 else 0\n",
    "            modified_stats['totlen_bwd_pkts'] = np.sum(bwd_weights) * flow_stats['bwd_pkt_len_mean']\n",
    "\n",
    "    # Aktualizacja sumarycznych statystyk przepływu\n",
    "    total_packets = modified_stats['tot_fwd_pkts'] + modified_stats['tot_bwd_pkts']\n",
    "    total_len = modified_stats['totlen_fwd_pkts'] + modified_stats['totlen_bwd_pkts']\n",
    "    modified_stats['pkt_len_mean'] = total_len / total_packets if total_packets > 0 else 0\n",
    "    pkt_lens = [modified_stats['fwd_pkt_len_mean']] * modified_stats['tot_fwd_pkts'] + \\\n",
    "               [modified_stats['bwd_pkt_len_mean']] * modified_stats['tot_bwd_pkts']\n",
    "    modified_stats['pkt_len_std'] = np.std(pkt_lens) if pkt_lens else 0\n",
    "\n",
    "    return modified_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tot_fwd_pkts': 1090,\n",
       " 'tot_bwd_pkts': 635,\n",
       " 'totlen_fwd_pkts': 65646,\n",
       " 'totlen_bwd_pkts': 1209780,\n",
       " 'fwd_pkt_len_max': 174,\n",
       " 'fwd_pkt_len_min': 60,\n",
       " 'fwd_pkt_len_mean': 60.225688073394494,\n",
       " 'fwd_pkt_len_std': 4.885710369123273,\n",
       " 'bwd_pkt_len_max': 4434,\n",
       " 'bwd_pkt_len_min': 60,\n",
       " 'bwd_pkt_len_mean': 1905.1653543307086,\n",
       " 'bwd_pkt_len_std': 701.5260190007999,\n",
       " 'pkt_len_mean': 739.3773913043478,\n",
       " 'pkt_len_std': 986.3701563824255}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_size_stats(truncated_packets, flow_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tot_fwd_pkts': 1090,\n",
       " 'tot_bwd_pkts': 635,\n",
       " 'totlen_fwd_pkts': 77154.05579771542,\n",
       " 'totlen_bwd_pkts': 1421718.408291247,\n",
       " 'fwd_pkt_len_max': 102.38366972477064,\n",
       " 'fwd_pkt_len_min': 60.225845183226525,\n",
       " 'fwd_pkt_len_mean': 70.78353742909673,\n",
       " 'fwd_pkt_len_std': 1.1565894641793688,\n",
       " 'bwd_pkt_len_max': 3238.7811023622044,\n",
       " 'bwd_pkt_len_min': 1905.1703242540664,\n",
       " 'bwd_pkt_len_mean': 2238.9266272303103,\n",
       " 'bwd_pkt_len_std': 166.04512531519813,\n",
       " 'pkt_len_mean': 868.9115733849058,\n",
       " 'pkt_len_std': 1045.6803642392474}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjust_packet_size_approx(prepare_size_stats(truncated_packets, flow_id), direction = 0, scaling_factor= 1.7, focus_point='middle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_packet_size_and_calculate_stats(truncated_packets, flow_id, direction=0, method='uniform', scaling_factor=1.0, focus_point='middle'):\n",
    "    \"\"\"\n",
    "    Przyjmuje listę obiektów pakietów oraz flow_id, filtruje pakiety na podstawie flow_id,\n",
    "    modyfikuje ich rozmiary na podstawie wybranej metody perturbacji i kierunku,\n",
    "    i zwraca zaktualizowane i kompleksowe statystyki przepływu dla wszystkich pakietów.\n",
    "    \"\"\"\n",
    "    # Filtracja pakietów na podstawie flow_id\n",
    "    packets = [pkt for pkt in truncated_packets if pkt.flow_id == flow_id]\n",
    "    \n",
    "    # Przygotowanie do obliczenia wag\n",
    "    if direction == 0:\n",
    "        direction_packets = packets\n",
    "    else:\n",
    "        direction_packets = [pkt for pkt in packets if pkt.direction == direction]\n",
    "    total_direction_packets = len(direction_packets)\n",
    "\n",
    "    # Obliczenie wag\n",
    "    if total_direction_packets > 0:\n",
    "        if method == 'normal':\n",
    "            weights = generate_weights(total_direction_packets, focus_point=focus_point, scaling_factor=scaling_factor)\n",
    "        else:  # 'uniform'\n",
    "            weights = np.full(total_direction_packets, scaling_factor)\n",
    "\n",
    "        # Modyfikacja rozmiarów pakietów w wybranym kierunku\n",
    "        for i, pkt in enumerate(direction_packets):\n",
    "            pkt.size = int(pkt.size * weights[i])  # Zaaktualizuj rozmiar pakietu\n",
    "\n",
    "    # Obliczanie statystyk dla wszystkich pakietów po modyfikacji\n",
    "    fwd_packets = [pkt for pkt in packets if pkt.direction == 1]\n",
    "    bwd_packets = [pkt for pkt in packets if pkt.direction == 2]\n",
    "\n",
    "    def calculate_stats(packets):\n",
    "        if packets:\n",
    "            sizes = [pkt.size for pkt in packets]\n",
    "            return {\n",
    "                'mean': np.mean(sizes),\n",
    "                'min': np.min(sizes),\n",
    "                'max': np.max(sizes),\n",
    "                'std': np.std(sizes),\n",
    "                'total_len': np.sum(sizes),\n",
    "                'count': len(sizes),\n",
    "            }\n",
    "        return {'mean': 0, 'min': 0, 'max': 0, 'std': 0, 'total_len': 0, 'count': 0}\n",
    "\n",
    "    fwd_stats = calculate_stats(fwd_packets)\n",
    "    bwd_stats = calculate_stats(bwd_packets)\n",
    "    all_stats = calculate_stats(packets)\n",
    "\n",
    "    updated_stats = {\n",
    "        'tot_fwd_pkts': fwd_stats['count'],\n",
    "        'tot_bwd_pkts': bwd_stats['count'],\n",
    "        'totlen_fwd_pkts': fwd_stats['total_len'],\n",
    "        'totlen_bwd_pkts': bwd_stats['total_len'],\n",
    "        'fwd_pkt_len_max': fwd_stats['max'],\n",
    "        'fwd_pkt_len_min': fwd_stats['min'],\n",
    "        'fwd_pkt_len_mean': fwd_stats['mean'],\n",
    "        'fwd_pkt_len_std': fwd_stats['std'],\n",
    "        'bwd_pkt_len_max': bwd_stats['max'],\n",
    "        'bwd_pkt_len_min': bwd_stats['min'],\n",
    "        'bwd_pkt_len_mean': bwd_stats['mean'],\n",
    "        'bwd_pkt_len_std': bwd_stats['std'],\n",
    "        'pkt_len_mean': all_stats['mean'],\n",
    "        'pkt_len_min': min(fwd_stats['min'], bwd_stats['min']) if fwd_stats['min'] and bwd_stats['min'] else max(fwd_stats['min'], bwd_stats['min']),\n",
    "        'pkt_len_max': max(fwd_stats['max'], bwd_stats['max']),\n",
    "        'pkt_len_std': all_stats['std'],\n",
    "    }\n",
    "\n",
    "    return updated_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tot_fwd_pkts': 2,\n",
       " 'tot_bwd_pkts': 1,\n",
       " 'totlen_fwd_pkts': 33908494036.969864,\n",
       " 'totlen_bwd_pkts': 35518673921.40699,\n",
       " 'fwd_pkt_len_max': 16954247018.484932,\n",
       " 'fwd_pkt_len_min': 16954247018.484932,\n",
       " 'fwd_pkt_len_mean': 16954247018.484932,\n",
       " 'fwd_pkt_len_std': 0.0,\n",
       " 'bwd_pkt_len_max': 35518673921.40699,\n",
       " 'bwd_pkt_len_min': 35518673921.40699,\n",
       " 'bwd_pkt_len_mean': 35518673921.40699,\n",
       " 'bwd_pkt_len_std': 0.0,\n",
       " 'pkt_len_mean': 23142389319.458954,\n",
       " 'pkt_len_std': 8751354767.93211}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjust_packet_size_and_calculate_stats(truncated_packets, flow_id,direction = 0, method='uniform', scaling_factor= 1.7, focus_point='middle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tot_fwd_pkts': 2,\n",
       " 'tot_bwd_pkts': 1,\n",
       " 'totlen_fwd_pkts': 1432,\n",
       " 'totlen_bwd_pkts': 1500,\n",
       " 'fwd_pkt_len_max': 716,\n",
       " 'fwd_pkt_len_min': 716,\n",
       " 'fwd_pkt_len_mean': 716.0,\n",
       " 'fwd_pkt_len_std': 0.0,\n",
       " 'bwd_pkt_len_max': 1500,\n",
       " 'bwd_pkt_len_min': 1500,\n",
       " 'bwd_pkt_len_mean': 1500.0,\n",
       " 'bwd_pkt_len_std': 0.0,\n",
       " 'pkt_len_mean': 977.3333333333334,\n",
       " 'pkt_len_std': 369.58114430016883}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjust_packet_size(truncated_packets, flow_id, direction = 0, method='uniform', scaling_factor= 1.7, focus_point='middle')\n",
    "\n",
    "prepare_size_stats(truncated_packets, flow_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyberaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
